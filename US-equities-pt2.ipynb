{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path \n",
    "import pandas_datareader.data as web\n",
    "import datetime \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats.mstats import gmean\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# unfortunately web APIs have query limits, so we switch to grabbing data from a downloaded database and may slight\n",
    "# corresponding adjustments. each stock's data is contained in its own file and has the same columns of interest as\n",
    "# are returned from the web query\n",
    "\n",
    "def grab_data(file):\n",
    "    \n",
    "    path = './stock-data/Stocks/'+file\n",
    "    data = pd.read_csv(path)\n",
    "    data.Date = data.Date.apply(lambda x: np.datetime64(x))\n",
    "    data.set_index('Date',inplace=True)\n",
    "    \n",
    "    return data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class stock:\n",
    "    def __init__(self,file):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.ticker = file[:-7]\n",
    "        self.data = grab_data(file)\n",
    "            \n",
    "    def grab_returns(self,window=1,featurelength=255):\n",
    "        self.window=window\n",
    "        self.featurelength = featurelength\n",
    "        self.returns = (self.data.loc[self.data.index>=start][window:].reset_index().Close-\\\n",
    "                             self.data.loc[self.data.index>=start][:-window].reset_index().Close)/\\\n",
    "                             self.data.loc[self.data.index>=start][:-window].reset_index().Close\n",
    "        self.returns.index = self.data.loc[self.data.index>=start][window:].index\n",
    "        self.maxreturn = self.returns.max()\n",
    "        self.maxend = np.datetime64(self.returns[self.returns==self.maxreturn].index[0])\n",
    "        self.maxbegin = self.data[(self.data.index<=self.maxend)][-(self.window):-(self.window-1)].index[0]\n",
    "        self.maxreturndata = self.data.loc[(self.data.index<=self.maxend)&(self.data.index>=(self.maxbegin))]\n",
    "        self.maxoneyear = self.data[(self.data.index<=self.maxend) & (self.data.index>=(self.maxbegin-np.timedelta64(366,'D')))]\n",
    "        self.featurewindow = self.data[self.data.index<self.maxbegin][-(featurelength+200):]\n",
    "        self.featurewindow['MA200'] = self.featurewindow.Close.rolling(window=200).mean()\n",
    "        self.featurewindow['MA100'] = self.featurewindow.Close.rolling(window=100).mean()\n",
    "        self.featurewindow['MA50'] = self.featurewindow.Close.rolling(window=50).mean()\n",
    "        self.featurewindow['MA20'] = self.featurewindow.Close.rolling(window=20).mean()\n",
    "        self.featurewindow['MA10'] = self.featurewindow.Close.rolling(window=10).mean()\n",
    "        self.featurewindow = self.featurewindow[-(featurelength+1):].drop(['Open','High','Low','OpenInt'],axis=1)\n",
    "        self.featurewindow['index'] = list(range(len(self.featurewindow)))\n",
    "        self.featurewindow.set_index('index',append=True,inplace=True)\n",
    "        self.featurewindowP = self.data[(self.data.index>self.maxend)][:featurelength]\n",
    "        \n",
    "        \n",
    "    def normalize(self,mode='avg'):\n",
    "        if mode=='pct':\n",
    "            self.featurewindow.loc[:,'Close'] = self.featurewindow.pct_change().loc[:,'Close']\n",
    "            self.featurewindow.loc[:,'MA200'] = self.featurewindow.pct_change().loc[:,'MA200']\n",
    "            self.featurewindow.loc[:,'MA100'] = self.featurewindow.pct_change().loc[:,'MA100']\n",
    "            self.featurewindow.loc[:,'MA50'] = self.featurewindow.pct_change().loc[:,'MA50']\n",
    "            self.featurewindow.loc[:,'MA20'] = self.featurewindow.pct_change().loc[:,'MA20']\n",
    "            self.featurewindow.loc[:,'MA10'] = self.featurewindow.pct_change().loc[:,'MA10']\n",
    "            self.featurewindow.dropna(inplace=True)\n",
    "            \n",
    "        if mode=='avg':\n",
    "            for col in self.featurewindow.columns:\n",
    "                if col == 'Volume':\n",
    "                    continue\n",
    "                self.featurewindow.loc[:,col] = (self.featurewindow[col]-self.featurewindow[col].mean())/self.featurewindow[col].std()\n",
    "        \n",
    "            for col in self.featurewindowP.columns:\n",
    "                self.featurewindowP.loc[:,col] = (self.featurewindowP[col]-self.featurewindowP[col].mean())/self.featurewindowP[col].std()\n",
    "            \n",
    "            for col in self.maxreturndata.columns:\n",
    "                self.maxreturndata.loc[:,col] = (self.maxreturndata[col]-self.maxreturndata[col].mean())/self.maxreturndata[col].std()\n",
    "            \n",
    "    def engineer_features(self,mode='basic',count=2):\n",
    "        self.features = []\n",
    "        \n",
    "        if mode == 'basic':\n",
    "            for col in self.featurewindow.columns:\n",
    "                self.features += list(self.featurewindow[col])\n",
    "                \n",
    "        if mode == 'discrete':\n",
    "            points = []\n",
    "            for k in range(count):\n",
    "                points.append(int(len(self.featurewindow)/(count-1))*k)\n",
    "            points[len(points)-1] = self.featurelength-1\n",
    "            self.featuretemp = self.featurewindow.iloc[points].copy()\n",
    "            for col in self.featuretemp.columns:\n",
    "                self.features += list(self.featuretemp[col])\n",
    "            del self.featuretemp\n",
    "            \n",
    "        if mode == 'interval': # only takes the avg closing prices (should normalize first) and volume over the intervals\n",
    "            points = []\n",
    "            for k in range(count):\n",
    "                points.append(int(len(self.featurewindow)/(count))*k)\n",
    "            points[len(points)-1] = self.featurelength-1\n",
    "            for k in range((count-1)):\n",
    "                self.features += [self.featurewindow.iloc[points[k]:points[k+1]].Close.mean()]\n",
    "            for k in range((count-1)):\n",
    "                self.features += [self.featurewindow.iloc[points[k]:points[k+1]].Volume.mean()]\n",
    "                \n",
    "        if mode == 'interval_g': # take the geometric mean of daily returns over each interval. need to normalize to %s first\n",
    "            points = []\n",
    "            for k in range(count):\n",
    "                points.append(int(len(self.featurewindow)/(count-1))*k)\n",
    "            points[len(points)-1] = self.featurelength-1\n",
    "            for k in range((count-1)):\n",
    "                if k == (count - 2):\n",
    "                        self.features += [gmean(self.featurewindow.iloc[points[k]:(points[k+1]+1)].Close+1)-1]\n",
    "                        continue\n",
    "                self.features += [gmean(self.featurewindow.iloc[points[k]:points[k+1]].Close+1)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.0018555437942200381]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = stock('aapl.us.txt')\n",
    "s.grab_returns(window=25)\n",
    "s.normalize(mode='pct')\n",
    "s.engineer_features(mode='interval_g',count=2)\n",
    "s.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pablo\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:315: RuntimeWarning: Mean of empty slice.\n",
      "  return np.exp(log_a.mean(axis=axis))\n",
      "C:\\Users\\Pablo\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "k1 = 2\n",
    "k2 = 3\n",
    "k3 = 5\n",
    "\n",
    "stock_df1 = pd.DataFrame(columns=list(range(k1-1)))\n",
    "stock_df2 = pd.DataFrame(columns=list(range(k2-1)))\n",
    "stock_df3 = pd.DataFrame(columns=list(range(k3-1)))\n",
    "\n",
    "for file in os.listdir('./stock-data/Stocks')[:100]:\n",
    "    try:\n",
    "        stk = stock(file)\n",
    "        stk.grab_returns(window=25)\n",
    "        stk.normalize(mode='pct')\n",
    "        \n",
    "        stk.engineer_features(mode='interval_g',count=k1)\n",
    "        temp1 = [stk.ticker.upper()]+[stk.featurewindow.index.get_level_values(0)[0]]+stk.features\n",
    "        stock_df1 = stock_df1.append(pd.DataFrame(temp1).transpose())\n",
    "        \n",
    "        stk.engineer_features(mode='interval_g',count=k2)\n",
    "        temp2 = [stk.ticker.upper()]+stk.features\n",
    "        stock_df2 = stock_df2.append(pd.DataFrame(temp2).transpose())\n",
    "        \n",
    "        stk.engineer_features(mode='interval_g',count=k3)\n",
    "        temp3 = [stk.ticker.upper()]+stk.features\n",
    "        stock_df3 = stock_df3.append(pd.DataFrame(temp3).transpose())\n",
    "        del stk\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "stock_df1.columns=(['ticker','begin_date']+list(range(len(stock_df1.columns)-2)))\n",
    "stock_df1 = stock_df1.set_index(['ticker','begin_date'])\n",
    "symbols_dates = stock_df1.drop(0,axis=1).copy()\n",
    "stock_df1.reset_index(inplace=True)\n",
    "stock_df1.drop('begin_date',axis=1,inplace=True)\n",
    "stock_df1.set_index('ticker',inplace=True)\n",
    "\n",
    "stock_df2.columns=(['ticker']+list(range(len(stock_df2.columns)-1)))\n",
    "stock_df2 = stock_df2.set_index('ticker')\n",
    "\n",
    "stock_df3.columns=(['ticker']+list(range(len(stock_df3.columns)-1)))\n",
    "stock_df3 = stock_df3.set_index('ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#symbols_dates.to_csv('./first-sample/symbols-dates.csv')\n",
    "#stock_df1.to_csv('./first-sample/df1.csv',index=False)\n",
    "#stock_df2.to_csv('./first-sample/df2.csv',index=False)\n",
    "#stock_df3.to_csv('./first-sample/df3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "KM1 = KMeans(n_clusters=3,random_state=2).fit(stock_df1.values)\n",
    "KM2 = KMeans(n_clusters=10,random_state=2).fit(stock_df2.values)\n",
    "KM3 = KMeans(n_clusters=10,random_state=2).fit(stock_df3.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intermediate_labels = pd.DataFrame()\n",
    "\n",
    "intermediate_labels['one'] = KM1.labels_\n",
    "intermediate_labels['two'] = KM2.labels_\n",
    "intermediate_labels['four'] = KM3.labels_\n",
    "\n",
    "merge_list = [pd.get_dummies(intermediate_labels.one),\n",
    "              pd.get_dummies(intermediate_labels.two),\n",
    "              pd.get_dummies(intermediate_labels.four)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummies = pd.concat(merge_list,axis=1)\n",
    "dummies.columns = list(range(23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KM_FINAL = KMeans(n_clusters=10,random_state=2).fit(dummies.values)\n",
    "stock_df1['FINAL_LABELS'] = KM_FINAL.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(stock_df1[stock_df1['FINAL_LABELS']==6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with this \"ensemble clustering\" approach, the results are a bit less interpretable. they may not necessarily have\n",
    "# similar price behavior throughout the period, but they were placed in a 'significant' number of the same clusters\n",
    "# when we cluster by 1, 2, and 4 periods over the window\n",
    "\n",
    "# aside -- the timelines below are all during the '07 - '09 crisis\n",
    "\n",
    "fig = plt.figure(figsize=(25,50))\n",
    "\n",
    "for i,tck in enumerate(stock_df1[stock_df1['FINAL_LABELS']==6].index):\n",
    "    \n",
    "    b = stock(start,end,tck)\n",
    "    b.grab_returns(window=25)\n",
    "    \n",
    "    ax1 = fig.add_subplot(10,1,i+1)\n",
    "    \n",
    "    ax1.plot(b.maxoneyear.index.get_level_values(0),b.maxoneyear.Close,'k',linewidth=1)\n",
    "    ax1.plot(b.featurewindow.index.get_level_values(0),b.featurewindow.MA200,'#db2000',linewidth=1)\n",
    "    ax1.plot(b.featurewindow.index.get_level_values(0),b.featurewindow.MA100,'#db4800',linewidth=1)\n",
    "    ax1.plot(b.featurewindow.index.get_level_values(0),b.featurewindow.MA50,'#db7100',linewidth=1)\n",
    "    ax1.plot(b.featurewindow.index.get_level_values(0),b.featurewindow.MA10,'#db7800',linewidth=1)\n",
    "    ax1.axvspan(b.maxbegin,b.maxend,facecolor='k',alpha=0.05)\n",
    "    ax1.set_title(tck+': 1 year prior to max '+str(b.window)+' day return',fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cluster with the second most count -- the technique seems to find pretty good similarities in price behavior\n",
    "\n",
    "fig = plt.figure(figsize=(25,50))\n",
    "\n",
    "for i,tck in enumerate(stock_df1[stock_df1['FINAL_LABELS']==2].index):\n",
    "    \n",
    "    b = stock(start,end,tck)\n",
    "    b.grab_returns(window=25)\n",
    "    \n",
    "    ax1 = fig.add_subplot(10,1,i+1)\n",
    "    \n",
    "    ax1.plot(b.maxoneyear.index.get_level_values(0),b.maxoneyear.Close,'k',linewidth=1)\n",
    "    ax1.plot(b.featurewindow.index.get_level_values(0),b.featurewindow.MA200,'#db2000',linewidth=1)\n",
    "    ax1.plot(b.featurewindow.index.get_level_values(0),b.featurewindow.MA100,'#db4800',linewidth=1)\n",
    "    ax1.plot(b.featurewindow.index.get_level_values(0),b.featurewindow.MA50,'#db7100',linewidth=1)\n",
    "    ax1.plot(b.featurewindow.index.get_level_values(0),b.featurewindow.MA10,'#db7800',linewidth=1)\n",
    "    ax1.axvspan(b.maxbegin,b.maxend,facecolor='k',alpha=0.05)\n",
    "    ax1.set_title(tck+': 1 year prior to max '+str(b.window)+' day return',fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
